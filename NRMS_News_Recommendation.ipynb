{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fri2tZK58vdc",
    "outputId": "e702146a-8dba-40b6-fbde-f4c392385348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.16 (default, Mar  2 2023, 03:18:16) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "# import tensorflow as tf\n",
    "\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "# from recommenders.models.newsrec.models.nrms import NRMSModel\n",
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "# print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RuUnLzSX87tO"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path is set to: C:\\Users\\Rija Farooqui\\Desktop\\news_recommendation\\recommenders\\recommenders\\data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the name of the directory\n",
    "directory = \"recommenders\\data\"\n",
    "\n",
    "# Specify the current path\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Full path\n",
    "data_path = os.path.join(current_path, directory)\n",
    "\n",
    "# Create the new directory\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "print(f\"Data path is set to: {data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lvoO6iF_gU8",
    "outputId": "0e37bba8-586f-454c-95b8-04f5bbd1d0be"
   },
   "outputs": [],
   "source": [
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
    "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\", r'nrms.yaml')\n",
    "\n",
    "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # specify the path to your .pkl file\n",
    "# file_path = wordEmb_file\n",
    "\n",
    "# # open and read the pickle file\n",
    "# with open(file_path, 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# # print or inspect the content of the pickle file\n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, \\\n",
    "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
    "                               os.path.join(data_path, 'utils'), mind_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BO3gt2EaWJdi",
    "outputId": "3827b437-0cea-4f2b-dbd6-7b1592c24d1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'support_quick_scoring': True, 'dropout': 0.2, 'attention_hidden_dim': 200, 'head_num': 20, 'head_dim': 20, 'filter_num': 200, 'window_size': 3, 'vert_emb_dim': 100, 'subvert_emb_dim': 100, 'gru_unit': 400, 'type': 'ini', 'user_emb_dim': 50, 'learning_rate': 0.0001, 'optimizer': 'adam', 'epochs': 5, 'batch_size': 1, 'show_step': 10, 'title_size': 30, 'his_size': 50, 'data_format': 'news', 'npratio': 4, 'metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'word_emb_dim': 300, 'model_type': 'nrms', 'loss': 'cross_entropy_loss', 'wordEmb_file': 'C:\\\\Users\\\\Rija Farooqui\\\\Desktop\\\\news_recommendation\\\\recommenders\\\\recommenders\\\\data\\\\utils\\\\embedding.npy', 'wordDict_file': 'C:\\\\Users\\\\Rija Farooqui\\\\Desktop\\\\news_recommendation\\\\recommenders\\\\recommenders\\\\data\\\\utils\\\\word_dict.pkl', 'userDict_file': 'C:\\\\Users\\\\Rija Farooqui\\\\Desktop\\\\news_recommendation\\\\recommenders\\\\recommenders\\\\data\\\\utils\\\\uid2index.pkl'}\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file, \n",
    "                          wordEmb_file=wordEmb_file,\n",
    "                          wordDict_file=wordDict_file, \n",
    "                          userDict_file=userDict_file,\n",
    "                          batch_size=1,\n",
    "                          epochs=epochs,\n",
    "                          show_step=10)\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8-5UiSpIWMQI"
   },
   "outputs": [],
   "source": [
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "iterator = MINDIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iterator(hparams, hparams.npratio, col_spliter=\"\\t\")\n",
    "batches = it.load_data_from_file(train_news_file, train_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 30)\n"
     ]
    }
   ],
   "source": [
    "for b in batches:\n",
    "    print(b['candidate_title_batch'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class AttLayer2(nn.Module):\n",
    "    def __init__(self, dim=200):\n",
    "        super(AttLayer2, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.W = nn.Parameter(torch.randn(dim, dim))\n",
    "        self.b = nn.Parameter(torch.randn(dim))\n",
    "        self.q = nn.Parameter(torch.randn(dim, 1))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        e = torch.tanh(torch.matmul(x, self.W) + self.b)\n",
    "        e = torch.matmul(e, self.q)\n",
    "        e = torch.squeeze(e, dim=-1)\n",
    "\n",
    "        if mask is not None:\n",
    "            e = e.masked_fill(mask==0, float('-inf'))\n",
    "\n",
    "        a = torch.softmax(e, dim=-1)\n",
    "\n",
    "        weighted_input = x * a.unsqueeze(-1)\n",
    "        return torch.sum(weighted_input, dim=1)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mask_right=False):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.mask_right = mask_right\n",
    "\n",
    "        self.W = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "\n",
    "    def forward(self, input_seq, input_seq_len):\n",
    "        input_seq = self.W(input_seq)\n",
    "\n",
    "        if self.mask_right:\n",
    "            mask = torch.triu(torch.ones((input_seq_len, input_seq_len)), diagonal=1).bool().to(input_seq.device)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        attn_output, _ = self.multihead_attn(input_seq, input_seq, input_seq, attn_mask = mask)\n",
    "\n",
    "        return attn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NRMSModel(torch.nn.Module):\n",
    "    def __init__(self, hparams, embed_model_name, freeze_embeddings=False):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.embedding = AutoModel.from_pretrained(embed_model_name)\n",
    "\n",
    "#         if freeze_embeddings:  # Freeze embeddings layer if specified\n",
    "#             for param in self.embedding.parameters():\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "        self.news_encoder = self._build_newsencoder()\n",
    "        self.user_encoder = self._build_userencoder()\n",
    "        \n",
    "        self.dot = torch.nn.CosineSimilarity(dim=-1)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def _build_newsencoder(self):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Dropout(self.hparams.dropout),\n",
    "            SelfAttention(self.hparams.head_num, self.hparams.head_dim),\n",
    "            torch.nn.Dropout(self.hparams.dropout),\n",
    "            AttLayer2(self.hparams.attention_hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def _build_userencoder(self):\n",
    "        return torch.nn.Sequential(\n",
    "            SelfAttention(self.hparams.head_num, self.hparams.head_dim),\n",
    "            AttLayer2(self.hparams.attention_hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        clicked_title_batch, candidate_title_batch = inputs\n",
    "        clicked_title_batch = self.embedding(clicked_title_batch)\n",
    "        candidate_title_batch = self.embedding(candidate_title_batch)\n",
    "        \n",
    "        user_present = self.user_encoder(clicked_title_batch)\n",
    "        news_present = self.news_encoder(candidate_title_batch)\n",
    "        \n",
    "        preds = self.softmax(self.dot(news_present, user_present.unsqueeze(1)))\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def score(self, clicked_title_batch, candidate_title_batch_one):\n",
    "        clicked_title_batch = self.embedding(clicked_title_batch)\n",
    "        candidate_title_batch_one = self.embedding(candidate_title_batch_one)\n",
    "        \n",
    "        user_present = self.user_encoder(clicked_title_batch)\n",
    "        news_present_one = self.news_encoder(candidate_title_batch_one.squeeze(1))\n",
    "        \n",
    "        pred_one = self.sigmoid(self.dot(news_present_one, user_present))\n",
    "        \n",
    "        return pred_one\n",
    "    def _get_input_label_from_iter(self, batch_data):\n",
    "        input_feat = [\n",
    "            batch_data[\"clicked_title_batch\"],\n",
    "            batch_data[\"candidate_title_batch\"],\n",
    "        ]\n",
    "        input_label = batch_data[\"labels\"]\n",
    "        return input_feat, input_label\n",
    "\n",
    "    def _get_user_feature_from_iter(self, batch_data):\n",
    "        return batch_data[\"clicked_title_batch\"]\n",
    "\n",
    "    def _get_news_feature_from_iter(self, batch_data):\n",
    "        return batch_data[\"candidate_title_batch\"]\n",
    "\n",
    "    def fit_model(self, dataloader, criterion, optimizer, num_epochs=10):\n",
    "        self.train()  # set the model in train mode\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for i, batch_data in enumerate(dataloader):\n",
    "                # Get the inputs and labels\n",
    "                inputs, labels = self._get_input_label_from_iter(batch_data)\n",
    "                inputs = [torch.tensor(inp).to(device) for inp in inputs]\n",
    "                labels = torch.tensor(labels).float().to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.forward(inputs)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Print statistics\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            print(f'Epoch {epoch+1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        print('Finished Training')\n",
    "model = NRMSModel(hparams, 'bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # or any other suitable loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Rija Farooqui\\AppData\\Local\\Temp\\ipykernel_22624\\109644038.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rija </span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">Farooqui\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22624\\\\109644038.py'</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Rija Farooqui\\AppData\\Local\\Temp\\ipykernel_22624\\2783060353.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">93</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit_model</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rija </span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">Farooqui\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22624\\\\2783060353.py'</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Rija Farooqui\\AppData\\Local\\Temp\\ipykernel_22624\\2783060353.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">43</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rija </span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">Farooqui\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22624\\\\2783060353.py'</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\Anaconda\\envs\\py36\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">D:\\Anaconda\\envs\\py36\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">974</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 971 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 972 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"You have to specify either input_ids or inputs_embeds\"</span>)     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 973 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 974 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batch_size, seq_length = input_shape                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 975 │   │   </span>device = input_ids.device <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> input_ids <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> inputs_embeds.device      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 976 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 977 │   │   # past_key_values_length</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>too many values to unpack <span style=\"font-weight: bold\">(</span>expected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Rija Farooqui\\AppData\\Local\\Temp\\ipykernel_22624\\109644038.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rija \u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31mFarooqui\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22624\\\\109644038.py'\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Rija Farooqui\\AppData\\Local\\Temp\\ipykernel_22624\\2783060353.py\u001b[0m:\u001b[94m93\u001b[0m in \u001b[92mfit_model\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rija \u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31mFarooqui\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22624\\\\2783060353.py'\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Rija Farooqui\\AppData\\Local\\Temp\\ipykernel_22624\\2783060353.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92mforward\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rija \u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31mFarooqui\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22624\\\\2783060353.py'\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mD:\\Anaconda\\envs\\py36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mD:\\Anaconda\\envs\\py36\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m:\u001b[94m974\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 971 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 972 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mYou have to specify either input_ids or inputs_embeds\u001b[0m\u001b[33m\"\u001b[0m)     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 973 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 974 \u001b[2m│   │   \u001b[0mbatch_size, seq_length = input_shape                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 975 \u001b[0m\u001b[2m│   │   \u001b[0mdevice = input_ids.device \u001b[94mif\u001b[0m input_ids \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m inputs_embeds.device      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 976 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 977 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# past_key_values_length\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mtoo many values to unpack \u001b[1m(\u001b[0mexpected \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit_model(batches, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Rija Farooqui\\AppData\\Local\\Temp\\ipykernel_22624\\1958521558.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rija </span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">Farooqui\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22624\\\\1958521558.py'</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">train</span><span style=\"font-weight: bold\">()</span> takes from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> positional arguments but <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> were given\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Rija Farooqui\\AppData\\Local\\Temp\\ipykernel_22624\\1958521558.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: 'C:\\\\Users\\\\Rija \u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31mFarooqui\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22624\\\\1958521558.py'\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mtrain\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m takes from \u001b[1;36m1\u001b[0m to \u001b[1;36m2\u001b[0m positional arguments but \u001b[1;36m4\u001b[0m were given\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(hparams.num_epochs):\n",
    "    model.train()  # Switch to training mode\n",
    "    train_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "\n",
    "        clicked_title_batch = batch['clicked_title_batch'].to(device)\n",
    "        candidate_title_batch = batch['candidate_title_batch'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(clicked_title_batch, candidate_title_batch)  # Forward pass\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Print training statistics\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss / len(train_loader)))\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()  # Switch to evaluation mode\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(valid_loader):\n",
    "            clicked_title_batch = batch['clicked_title_batch'].to(device)\n",
    "            candidate_title_batch = batch['candidate_title_batch'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(clicked_title_batch, candidate_title_batch)  # Forward pass\n",
    "\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    # Print validation statistics\n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}'.format(epoch, valid_loss / len(valid_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRhHVG3gWOBU",
    "outputId": "5e32a686-a01e-4cb1-da59-0f09b111be1d"
   },
   "outputs": [],
   "source": [
    "model = NRMSModel(hparams, iterator, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Bdcac0nWPCi",
    "outputId": "79addeb8-9fa9-4974-b265-8dbbe7ecb96d"
   },
   "outputs": [],
   "source": [
    "print(model.run_eval(valid_news_file, valid_behaviors_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2zOSbDjWQpi",
    "outputId": "0f5c2bfe-d0c6-4e40-8c6c-58d577142056"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIbawXSQZ5bZ",
    "outputId": "1f0bb18e-23a8-46b9-caf3-36fdae4c48ec"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
    "print(res_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kxg04VI4aITv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
